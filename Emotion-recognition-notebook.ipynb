{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/fer2013.csv')\n",
    "\n",
    "# print(df.info())\n",
    "# print(df[\"Usage\"].value_counts())\n",
    "\n",
    "# print(df.head())\n",
    "X_train,y_train,X_test,y_test=[],[],[],[]\n",
    "num_labels = 7\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           y_train.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           y_test.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "y_train = np.array(y_train,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "y_test = np.array(y_test,'float32')\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train, num_classes=num_labels)\n",
    "y_test=np_utils.to_categorical(y_test, num_classes=num_labels)\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28709"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "898/898 [==============================] - 267s 297ms/step - loss: 1.8612 - accuracy: 0.2639 - val_loss: 1.5796 - val_accuracy: 0.3948\n",
      "Epoch 2/200\n",
      "898/898 [==============================] - 274s 305ms/step - loss: 1.5640 - accuracy: 0.3903 - val_loss: 1.4184 - val_accuracy: 0.4469\n",
      "Epoch 3/200\n",
      "898/898 [==============================] - 308s 342ms/step - loss: 1.4375 - accuracy: 0.4391 - val_loss: 1.4174 - val_accuracy: 0.4419\n",
      "Epoch 4/200\n",
      "898/898 [==============================] - 298s 332ms/step - loss: 1.3641 - accuracy: 0.4744 - val_loss: 1.3297 - val_accuracy: 0.4817\n",
      "Epoch 5/200\n",
      "898/898 [==============================] - 413s 460ms/step - loss: 1.2954 - accuracy: 0.5054 - val_loss: 1.2659 - val_accuracy: 0.5121\n",
      "Epoch 6/200\n",
      "898/898 [==============================] - 427s 476ms/step - loss: 1.2442 - accuracy: 0.5247 - val_loss: 1.2252 - val_accuracy: 0.5302\n",
      "Epoch 7/200\n",
      "898/898 [==============================] - 373s 415ms/step - loss: 1.1925 - accuracy: 0.5422 - val_loss: 1.2142 - val_accuracy: 0.5352\n",
      "Epoch 8/200\n",
      "898/898 [==============================] - 329s 367ms/step - loss: 1.1693 - accuracy: 0.5545 - val_loss: 1.1962 - val_accuracy: 0.5514\n",
      "Epoch 9/200\n",
      "898/898 [==============================] - 299s 333ms/step - loss: 1.1196 - accuracy: 0.5748 - val_loss: 1.1938 - val_accuracy: 0.5556\n",
      "Epoch 10/200\n",
      "898/898 [==============================] - 303s 337ms/step - loss: 1.0738 - accuracy: 0.5878 - val_loss: 1.1691 - val_accuracy: 0.5692\n",
      "Epoch 11/200\n",
      "898/898 [==============================] - 396s 441ms/step - loss: 1.0504 - accuracy: 0.5949 - val_loss: 1.1922 - val_accuracy: 0.5620\n",
      "Epoch 12/200\n",
      "898/898 [==============================] - 331s 369ms/step - loss: 1.0070 - accuracy: 0.6184 - val_loss: 1.1951 - val_accuracy: 0.5603\n",
      "Epoch 13/200\n",
      "898/898 [==============================] - 285s 317ms/step - loss: 0.9944 - accuracy: 0.6188 - val_loss: 1.1741 - val_accuracy: 0.5798\n",
      "Epoch 14/200\n",
      "898/898 [==============================] - 315s 350ms/step - loss: 0.9389 - accuracy: 0.6428 - val_loss: 1.1974 - val_accuracy: 0.5706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d25d20ee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "num_labels = 7 \n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "#model.summary()\n",
    "\n",
    "#gen = ImageDataGenerator()\n",
    "#train_generator = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy'\n",
    "              , optimizer=Adam()\n",
    "              , metrics=['accuracy']\n",
    "             )\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#val_generator = val_datagen.flow(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "#Training the model\n",
    "#print(shape(X_train))\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "#model.fit_generator(train_generator, steps_per_epoch=len(X_train) // batch_size, epochs=epochs\n",
    "                   # , validation_data=val_generator, validation_steps= len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "898/898 [==============================] - 5s 6ms/step - loss: 1.5455 - accuracy: 0.3911 - val_loss: 1.3818 - val_accuracy: 0.4728\n",
      "Epoch 2/200\n",
      "898/898 [==============================] - 5s 6ms/step - loss: 1.3249 - accuracy: 0.4931 - val_loss: 1.2690 - val_accuracy: 0.5093\n",
      "Epoch 3/200\n",
      "898/898 [==============================] - 5s 6ms/step - loss: 1.2315 - accuracy: 0.5347 - val_loss: 1.2640 - val_accuracy: 0.5110\n",
      "Epoch 4/200\n",
      "898/898 [==============================] - 5s 5ms/step - loss: 1.1727 - accuracy: 0.5537 - val_loss: 1.2336 - val_accuracy: 0.5305\n",
      "Epoch 5/200\n",
      "898/898 [==============================] - 6s 7ms/step - loss: 1.1180 - accuracy: 0.5775 - val_loss: 1.1727 - val_accuracy: 0.5550\n",
      "Epoch 6/200\n",
      "898/898 [==============================] - 5s 6ms/step - loss: 1.0693 - accuracy: 0.5987 - val_loss: 1.1678 - val_accuracy: 0.5639\n",
      "Epoch 7/200\n",
      "898/898 [==============================] - 5s 6ms/step - loss: 1.0173 - accuracy: 0.6126 - val_loss: 1.1764 - val_accuracy: 0.5628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc8aa752390>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_labels = 7 \n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "model = Sequential()\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 0)\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    " \n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    " model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "#gen = ImageDataGenerator()\n",
    "#train_generator = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy'\n",
    "              , optimizer=Adam()\n",
    "              , metrics=['accuracy']\n",
    "             )\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#val_generator = val_datagen.flow(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "#Training the model\n",
    "#print(shape(X_train))\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "#model.fit_generator(train_generator, steps_per_epoch=len(X_train) // batch_size, epochs=epochs\n",
    "                   # , validation_data=val_generator, validation_steps= len(X_test) // batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7169216871261597\n",
      "Train accuracy: 72.74722456932068\n",
      "Test loss: 1.1973587274551392\n",
      "Test accuracy: 57.06325173377991\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
